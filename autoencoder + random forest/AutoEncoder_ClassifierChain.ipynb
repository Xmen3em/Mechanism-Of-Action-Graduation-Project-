{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b250d739",
   "metadata": {
    "papermill": {
     "duration": 0.006917,
     "end_time": "2024-02-25T18:44:21.970617",
     "exception": false,
     "start_time": "2024-02-25T18:44:21.963700",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf14bc01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-25T18:44:21.984217Z",
     "iopub.status.busy": "2024-02-25T18:44:21.983882Z",
     "iopub.status.idle": "2024-02-25T18:44:36.474468Z",
     "shell.execute_reply": "2024-02-25T18:44:36.473453Z"
    },
    "papermill": {
     "duration": 14.500133,
     "end_time": "2024-02-25T18:44:36.476900",
     "exception": false,
     "start_time": "2024-02-25T18:44:21.976767",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-07 23:49:27.265389: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-07 23:49:27.367076: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-03-07 23:49:27.367091: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-03-07 23:49:27.909400: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-03-07 23:49:27.909455: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-03-07 23:49:27.909461: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import pickle\n",
    "from skmultilearn.model_selection import iterative_train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Activation, Input, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d6e14a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-25T18:44:36.494662Z",
     "iopub.status.busy": "2024-02-25T18:44:36.493574Z",
     "iopub.status.idle": "2024-02-25T18:44:43.450992Z",
     "shell.execute_reply": "2024-02-25T18:44:43.449331Z"
    },
    "papermill": {
     "duration": 6.968227,
     "end_time": "2024-02-25T18:44:43.454065",
     "exception": false,
     "start_time": "2024-02-25T18:44:36.485838",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('/home/abdelmoneim/سطح المكتب/for graduation project/dataset/train_features.csv')\n",
    "test = pd.read_csv('/home/abdelmoneim/سطح المكتب/for graduation project/dataset/test_features.csv')\n",
    "scored_target =pd.read_csv('/home/abdelmoneim/سطح المكتب/for graduation project/dataset/train_targets_scored.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81d0f016",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-25T18:44:43.467436Z",
     "iopub.status.busy": "2024-02-25T18:44:43.467147Z",
     "iopub.status.idle": "2024-02-25T18:44:43.581304Z",
     "shell.execute_reply": "2024-02-25T18:44:43.580392Z"
    },
    "papermill": {
     "duration": 0.123234,
     "end_time": "2024-02-25T18:44:43.583531",
     "exception": false,
     "start_time": "2024-02-25T18:44:43.460297",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the length of gene features 772\n",
      "the lenght of cell features 100\n",
      "the length of all inputs and target dataset (23814, 1082)\n"
     ]
    }
   ],
   "source": [
    "# list of name of moa and remove sig_id\n",
    "target_cols = [col for col in scored_target.columns if col not in ['sig_id']]\n",
    "\n",
    "# separating cell features and gene features\n",
    "gene_features = []\n",
    "cell_features = []\n",
    "for i in train.columns:\n",
    "    if i.startswith('g-'):\n",
    "        gene_features.append(i)\n",
    "    if i.startswith('c-'):\n",
    "        cell_features.append(i)\n",
    "\n",
    "print('the length of gene features', len(gene_features))\n",
    "print('the lenght of cell features', len(cell_features))\n",
    "\n",
    "# marge train inputs and target\n",
    "train_merge = pd.merge(train, scored_target, on = 'sig_id', how = 'left')\n",
    "print('the length of all inputs and target dataset', train_merge.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f25cfef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-25T18:44:43.597066Z",
     "iopub.status.busy": "2024-02-25T18:44:43.596336Z",
     "iopub.status.idle": "2024-02-25T18:44:43.620888Z",
     "shell.execute_reply": "2024-02-25T18:44:43.619923Z"
    },
    "papermill": {
     "duration": 0.033335,
     "end_time": "2024-02-25T18:44:43.622911",
     "exception": false,
     "start_time": "2024-02-25T18:44:43.589576",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# encode categorical features in the train and test data\n",
    "le = LabelEncoder()\n",
    "\n",
    "train_merge['cp_type'] = le.fit_transform(train_merge['cp_type'])\n",
    "train_merge['cp_time'] = le.fit_transform(train_merge['cp_time'])\n",
    "train_merge['cp_dose'] = le.fit_transform(train_merge['cp_dose'])\n",
    "\n",
    "test['cp_type'] = le.fit_transform(test['cp_type'])\n",
    "test['cp_time'] = le.fit_transform(test['cp_time'])\n",
    "test['cp_dose'] = le.fit_transform(test['cp_dose'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e9c7ccb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-25T18:44:43.636150Z",
     "iopub.status.busy": "2024-02-25T18:44:43.635863Z",
     "iopub.status.idle": "2024-02-25T18:44:43.764787Z",
     "shell.execute_reply": "2024-02-25T18:44:43.763754Z"
    },
    "papermill": {
     "duration": 0.137568,
     "end_time": "2024-02-25T18:44:43.766818",
     "exception": false,
     "start_time": "2024-02-25T18:44:43.629250",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>cp_type</th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>g-0</th>\n",
       "      <th>g-1</th>\n",
       "      <th>g-2</th>\n",
       "      <th>g-3</th>\n",
       "      <th>g-4</th>\n",
       "      <th>g-5</th>\n",
       "      <th>...</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0620</td>\n",
       "      <td>0.5577</td>\n",
       "      <td>-0.2479</td>\n",
       "      <td>-0.6208</td>\n",
       "      <td>-0.1944</td>\n",
       "      <td>-1.0120</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0743</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.2991</td>\n",
       "      <td>0.0604</td>\n",
       "      <td>1.0190</td>\n",
       "      <td>0.5207</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6280</td>\n",
       "      <td>0.5817</td>\n",
       "      <td>1.5540</td>\n",
       "      <td>-0.0764</td>\n",
       "      <td>-0.0323</td>\n",
       "      <td>1.2390</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.5138</td>\n",
       "      <td>-0.2491</td>\n",
       "      <td>-0.2656</td>\n",
       "      <td>0.5288</td>\n",
       "      <td>4.0620</td>\n",
       "      <td>-0.8095</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.3254</td>\n",
       "      <td>-0.4009</td>\n",
       "      <td>0.9700</td>\n",
       "      <td>0.6919</td>\n",
       "      <td>1.4180</td>\n",
       "      <td>-0.8244</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1082 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sig_id  cp_type  cp_time  cp_dose     g-0     g-1     g-2     g-3  \\\n",
       "0  id_000644bb2        1        0        0  1.0620  0.5577 -0.2479 -0.6208   \n",
       "1  id_000779bfc        1        2        0  0.0743  0.4087  0.2991  0.0604   \n",
       "2  id_000a6266a        1        1        0  0.6280  0.5817  1.5540 -0.0764   \n",
       "3  id_0015fd391        1        1        0 -0.5138 -0.2491 -0.2656  0.5288   \n",
       "4  id_001626bd3        1        2        1 -0.3254 -0.4009  0.9700  0.6919   \n",
       "\n",
       "      g-4     g-5  ...  tropomyosin_receptor_kinase_inhibitor  trpv_agonist  \\\n",
       "0 -0.1944 -1.0120  ...                                      0             0   \n",
       "1  1.0190  0.5207  ...                                      0             0   \n",
       "2 -0.0323  1.2390  ...                                      0             0   \n",
       "3  4.0620 -0.8095  ...                                      0             0   \n",
       "4  1.4180 -0.8244  ...                                      0             0   \n",
       "\n",
       "   trpv_antagonist  tubulin_inhibitor  tyrosine_kinase_inhibitor  \\\n",
       "0                0                  0                          0   \n",
       "1                0                  0                          0   \n",
       "2                0                  0                          0   \n",
       "3                0                  0                          0   \n",
       "4                0                  0                          0   \n",
       "\n",
       "   ubiquitin_specific_protease_inhibitor  vegfr_inhibitor  vitamin_b  \\\n",
       "0                                      0                0          0   \n",
       "1                                      0                0          0   \n",
       "2                                      0                0          0   \n",
       "3                                      0                0          0   \n",
       "4                                      0                0          0   \n",
       "\n",
       "   vitamin_d_receptor_agonist  wnt_inhibitor  \n",
       "0                           0              0  \n",
       "1                           0              0  \n",
       "2                           0              0  \n",
       "3                           0              0  \n",
       "4                           0              0  \n",
       "\n",
       "[5 rows x 1082 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = train_merge.copy()\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7b3a87d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-25T18:44:43.781008Z",
     "iopub.status.busy": "2024-02-25T18:44:43.780714Z",
     "iopub.status.idle": "2024-02-25T18:44:43.799150Z",
     "shell.execute_reply": "2024-02-25T18:44:43.798026Z"
    },
    "papermill": {
     "duration": 0.028271,
     "end_time": "2024-02-25T18:44:43.801599",
     "exception": false,
     "start_time": "2024-02-25T18:44:43.773328",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = x[target_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "786ef81b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-25T18:44:43.816596Z",
     "iopub.status.busy": "2024-02-25T18:44:43.816238Z",
     "iopub.status.idle": "2024-02-25T18:44:43.822512Z",
     "shell.execute_reply": "2024-02-25T18:44:43.821664Z"
    },
    "papermill": {
     "duration": 0.01596,
     "end_time": "2024-02-25T18:44:43.824467",
     "exception": false,
     "start_time": "2024-02-25T18:44:43.808507",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((23814, 1082), (3982, 876), (23814, 206))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, test.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e94566",
   "metadata": {
    "papermill": {
     "duration": 0.006535,
     "end_time": "2024-02-25T18:44:43.837785",
     "exception": false,
     "start_time": "2024-02-25T18:44:43.831250",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## gene features - AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82df3473",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-25T18:44:43.853849Z",
     "iopub.status.busy": "2024-02-25T18:44:43.853548Z",
     "iopub.status.idle": "2024-02-25T18:44:44.685976Z",
     "shell.execute_reply": "2024-02-25T18:44:44.684961Z"
    },
    "papermill": {
     "duration": 0.843521,
     "end_time": "2024-02-25T18:44:44.688386",
     "exception": false,
     "start_time": "2024-02-25T18:44:43.844865",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# encoder part\n",
    "inputs = Input(shape = (772,))\n",
    "encoder_1 = Dense(512, activation = 'relu')(inputs)\n",
    "batch_norm = BatchNormalization()(encoder_1)\n",
    "encoder_2 = Dense(420, activation = 'relu')(batch_norm)\n",
    "\n",
    "# decoder part\n",
    "decodrer_1 = Dense(420, activation = 'relu')(encoder_2)\n",
    "batch_norm = BatchNormalization()(decodrer_1)\n",
    "decodrer_2 = Dense(512, activation = 'relu')(batch_norm)\n",
    "batch_norm = BatchNormalization()(decodrer_2)\n",
    "decoder_3 = Dense(772)(encoder_2)\n",
    "\n",
    "model = tf.keras.Model(inputs = inputs, outputs = decoder_3)\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c480d57d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-25T18:44:44.703635Z",
     "iopub.status.busy": "2024-02-25T18:44:44.703311Z",
     "iopub.status.idle": "2024-02-25T18:45:19.312368Z",
     "shell.execute_reply": "2024-02-25T18:45:19.311562Z"
    },
    "papermill": {
     "duration": 34.618946,
     "end_time": "2024-02-25T18:45:19.314379",
     "exception": false,
     "start_time": "2024-02-25T18:44:44.695433",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1708886687.766636      67 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 3s 9ms/step - loss: 1.0899\n",
      "Epoch 2/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.7397\n",
      "Epoch 3/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.6492\n",
      "Epoch 4/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.5931\n",
      "Epoch 5/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.5503\n",
      "Epoch 6/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.5195\n",
      "Epoch 7/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.4854\n",
      "Epoch 8/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.4590\n",
      "Epoch 9/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.4294\n",
      "Epoch 10/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3995\n",
      "Epoch 11/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3719\n",
      "Epoch 12/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3487\n",
      "Epoch 13/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3273\n",
      "Epoch 14/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3141\n",
      "Epoch 15/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2999\n",
      "Epoch 16/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2810\n",
      "Epoch 17/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2707\n",
      "Epoch 18/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2553\n",
      "Epoch 19/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.2471\n",
      "Epoch 20/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.2461\n",
      "Epoch 21/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2316\n",
      "Epoch 22/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2253\n",
      "Epoch 23/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2205\n",
      "Epoch 24/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2170\n",
      "Epoch 25/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2156\n",
      "Epoch 26/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2066\n",
      "Epoch 27/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2016\n",
      "Epoch 28/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2085\n",
      "Epoch 29/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1968\n",
      "Epoch 30/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1961\n",
      "Epoch 31/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1931\n",
      "Epoch 32/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1950\n",
      "Epoch 33/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1880\n",
      "Epoch 34/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1858\n",
      "Epoch 35/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1801\n",
      "Epoch 36/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1818\n",
      "Epoch 37/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1790\n",
      "Epoch 38/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1732\n",
      "Epoch 39/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1742\n",
      "Epoch 40/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1751\n",
      "Epoch 41/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1770\n",
      "Epoch 42/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1675\n",
      "Epoch 43/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1650\n",
      "Epoch 44/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1750\n",
      "Epoch 45/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1714\n",
      "Epoch 46/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1648\n",
      "Epoch 47/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1616\n",
      "Epoch 48/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1613\n",
      "Epoch 49/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1673\n",
      "Epoch 50/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1696\n",
      "Epoch 51/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1620\n",
      "Epoch 52/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1602\n",
      "Epoch 53/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1580\n",
      "Epoch 54/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1567\n",
      "Epoch 55/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1536\n",
      "Epoch 56/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1523\n",
      "Epoch 57/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1569\n",
      "Epoch 58/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1566\n",
      "Epoch 59/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1559\n",
      "Epoch 60/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1549\n",
      "Epoch 61/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1541\n",
      "Epoch 62/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1550\n",
      "Epoch 63/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1529\n",
      "Epoch 64/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1489\n",
      "Epoch 65/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1469\n",
      "Epoch 66/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1464\n",
      "Epoch 67/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1497\n",
      "Epoch 68/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1476\n",
      "Epoch 69/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1498\n",
      "Epoch 70/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1478\n",
      "Epoch 71/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1465\n",
      "Epoch 72/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1467\n",
      "Epoch 73/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1453\n",
      "Epoch 74/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1439\n",
      "Epoch 75/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1473\n",
      "Epoch 76/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1483\n",
      "Epoch 77/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1457\n",
      "Epoch 78/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1473\n",
      "Epoch 79/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1494\n",
      "Epoch 80/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1444\n",
      "Epoch 81/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1452\n",
      "Epoch 82/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1452\n",
      "Epoch 83/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1471\n",
      "Epoch 84/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1472\n",
      "Epoch 85/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1437\n",
      "Epoch 86/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1409\n",
      "Epoch 87/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1446\n",
      "Epoch 88/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1419\n",
      "Epoch 89/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1393\n",
      "Epoch 90/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1418\n",
      "Epoch 91/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1424\n",
      "Epoch 92/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1400\n",
      "Epoch 93/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1427\n",
      "Epoch 94/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1453\n",
      "Epoch 95/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1412\n",
      "Epoch 96/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1438\n",
      "Epoch 97/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1424\n",
      "Epoch 98/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1404\n",
      "Epoch 99/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1417\n",
      "Epoch 100/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1388\n",
      "Epoch 101/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1399\n",
      "Epoch 102/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1385\n",
      "Epoch 103/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1408\n",
      "Epoch 104/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1418\n",
      "Epoch 105/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1364\n",
      "Epoch 106/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1400\n",
      "Epoch 107/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1416\n",
      "Epoch 108/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1407\n",
      "Epoch 109/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1465\n",
      "Epoch 110/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1404\n",
      "Epoch 111/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1362\n",
      "Epoch 112/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1424\n",
      "Epoch 113/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1504\n",
      "Epoch 114/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1381\n",
      "Epoch 115/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1392\n",
      "Epoch 116/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1395\n",
      "Epoch 117/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.1385\n",
      "Epoch 118/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.1348\n",
      "Epoch 119/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1407\n",
      "Epoch 120/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1382\n",
      "Epoch 121/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1377\n",
      "Epoch 122/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1365\n",
      "Epoch 123/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1417\n",
      "Epoch 124/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1387\n",
      "Epoch 125/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.1382\n",
      "Epoch 126/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1416\n",
      "Epoch 127/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.1371\n",
      "Epoch 128/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1359\n",
      "Epoch 129/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1366\n",
      "Epoch 130/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1384\n",
      "Epoch 131/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.1357\n",
      "Epoch 132/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1349\n",
      "Epoch 133/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1364\n",
      "Epoch 134/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1353\n",
      "Epoch 135/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1368\n",
      "Epoch 136/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1375\n",
      "Epoch 137/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1427\n",
      "Epoch 138/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1387\n",
      "Epoch 139/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1356\n",
      "Epoch 140/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1349\n",
      "Epoch 141/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1338\n",
      "Epoch 142/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1356\n",
      "Epoch 143/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.1419\n",
      "Epoch 144/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.1372\n",
      "Epoch 145/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.1373\n",
      "Epoch 146/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.1384\n",
      "Epoch 147/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1392\n",
      "Epoch 148/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1355\n",
      "Epoch 149/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1334\n",
      "Epoch 150/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1340\n",
      "Epoch 151/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1346\n",
      "Epoch 152/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1367\n",
      "Epoch 153/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1336\n",
      "Epoch 154/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1354\n",
      "Epoch 155/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1371\n",
      "Epoch 156/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1330\n",
      "Epoch 157/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1375\n",
      "Epoch 158/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1329\n",
      "Epoch 159/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1341\n",
      "Epoch 160/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1337\n",
      "Epoch 161/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1331\n",
      "Epoch 162/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1343\n",
      "Epoch 163/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1326\n",
      "Epoch 164/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1340\n",
      "Epoch 165/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1319\n",
      "Epoch 166/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1319\n",
      "Epoch 167/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1322\n",
      "Epoch 168/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1330\n",
      "Epoch 169/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1351\n",
      "Epoch 170/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1351\n",
      "Epoch 171/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1365\n",
      "Epoch 172/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1329\n",
      "Epoch 173/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1407\n",
      "Epoch 174/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1341\n",
      "Epoch 175/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1370\n",
      "Epoch 176/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1339\n",
      "Epoch 177/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1336\n",
      "Epoch 178/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1338\n",
      "Epoch 179/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1314\n",
      "Epoch 180/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1333\n",
      "Epoch 181/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1340\n",
      "Epoch 182/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.1340\n",
      "Epoch 183/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1314\n",
      "Epoch 184/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1373\n",
      "Epoch 185/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1354\n",
      "Epoch 186/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1318\n",
      "Epoch 187/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1321\n",
      "Epoch 188/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1304\n",
      "Epoch 189/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1302\n",
      "Epoch 190/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1319\n",
      "Epoch 191/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1363\n",
      "Epoch 192/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1303\n",
      "Epoch 193/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1309\n",
      "Epoch 194/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1340\n",
      "Epoch 195/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1341\n",
      "Epoch 196/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1333\n",
      "Epoch 197/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1326\n",
      "Epoch 198/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.1323\n",
      "Epoch 199/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1320\n",
      "Epoch 200/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1350\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    model.fit(x[gene_features], x[gene_features], batch_size = 1000, epochs = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1627f99f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-25T18:45:19.499211Z",
     "iopub.status.busy": "2024-02-25T18:45:19.498704Z",
     "iopub.status.idle": "2024-02-25T18:45:19.536312Z",
     "shell.execute_reply": "2024-02-25T18:45:19.535184Z"
    },
    "papermill": {
     "duration": 0.138072,
     "end_time": "2024-02-25T18:45:19.538417",
     "exception": false,
     "start_time": "2024-02-25T18:45:19.400345",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# take the output of the encoded part\n",
    "encoder = tf.keras.Model(inputs = inputs, outputs = encoder_2)\n",
    "encoder.save('encoder_gene_features.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19624e9",
   "metadata": {
    "papermill": {
     "duration": 0.088949,
     "end_time": "2024-02-25T18:45:19.712443",
     "exception": false,
     "start_time": "2024-02-25T18:45:19.623494",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## cell features - AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e84c8d05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-25T18:45:19.943620Z",
     "iopub.status.busy": "2024-02-25T18:45:19.943221Z",
     "iopub.status.idle": "2024-02-25T18:45:20.068266Z",
     "shell.execute_reply": "2024-02-25T18:45:20.067327Z"
    },
    "papermill": {
     "duration": 0.27071,
     "end_time": "2024-02-25T18:45:20.070446",
     "exception": false,
     "start_time": "2024-02-25T18:45:19.799736",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# encoder part\n",
    "inputs = Input(shape = (100,))\n",
    "encoder_1 = Dense(90, activation = 'relu')(inputs)\n",
    "batch_norm = BatchNormalization()(encoder_1)\n",
    "encoder_2 = Dense(75, activation = 'relu')(batch_norm)\n",
    "\n",
    "# decoder part\n",
    "decodrer_1 = Dense(75, activation = 'relu')(encoder_2)\n",
    "batch_norm = BatchNormalization()(decodrer_1)\n",
    "decodrer_2 = Dense(90, activation = 'relu')(batch_norm)\n",
    "batch_norm = BatchNormalization()(decodrer_2)\n",
    "decoder_3 = Dense(100)(encoder_2)\n",
    "\n",
    "model = tf.keras.Model(inputs = inputs, outputs = decoder_3)\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bad048a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-25T18:45:20.240420Z",
     "iopub.status.busy": "2024-02-25T18:45:20.240007Z",
     "iopub.status.idle": "2024-02-25T18:45:39.757881Z",
     "shell.execute_reply": "2024-02-25T18:45:39.756955Z"
    },
    "papermill": {
     "duration": 19.605574,
     "end_time": "2024-02-25T18:45:39.759914",
     "exception": false,
     "start_time": "2024-02-25T18:45:20.154340",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "24/24 [==============================] - 2s 4ms/step - loss: 2.8981\n",
      "Epoch 2/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.8344\n",
      "Epoch 3/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.5924\n",
      "Epoch 4/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.5500\n",
      "Epoch 5/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.5285\n",
      "Epoch 6/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.5176\n",
      "Epoch 7/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.4930\n",
      "Epoch 8/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.4821\n",
      "Epoch 9/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.4611\n",
      "Epoch 10/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.4408\n",
      "Epoch 11/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.4208\n",
      "Epoch 12/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.4327\n",
      "Epoch 13/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.4071\n",
      "Epoch 14/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.3954\n",
      "Epoch 15/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.3909\n",
      "Epoch 16/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.3901\n",
      "Epoch 17/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.3775\n",
      "Epoch 18/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.3771\n",
      "Epoch 19/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.3607\n",
      "Epoch 20/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.3592\n",
      "Epoch 21/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.3456\n",
      "Epoch 22/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.3409\n",
      "Epoch 23/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.3306\n",
      "Epoch 24/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.3336\n",
      "Epoch 25/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.3277\n",
      "Epoch 26/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.3229\n",
      "Epoch 27/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.3174\n",
      "Epoch 28/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.3055\n",
      "Epoch 29/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.3019\n",
      "Epoch 30/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.3013\n",
      "Epoch 31/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.2882\n",
      "Epoch 32/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.2870\n",
      "Epoch 33/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.2819\n",
      "Epoch 34/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.2915\n",
      "Epoch 35/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.2756\n",
      "Epoch 36/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.2689\n",
      "Epoch 37/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.2602\n",
      "Epoch 38/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.2683\n",
      "Epoch 39/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.2479\n",
      "Epoch 40/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.2537\n",
      "Epoch 41/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.2404\n",
      "Epoch 42/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.2376\n",
      "Epoch 43/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.2586\n",
      "Epoch 44/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.2393\n",
      "Epoch 45/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.2355\n",
      "Epoch 46/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.2278\n",
      "Epoch 47/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.2289\n",
      "Epoch 48/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.2121\n",
      "Epoch 49/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.2105\n",
      "Epoch 50/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.2150\n",
      "Epoch 51/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.2076\n",
      "Epoch 52/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.2108\n",
      "Epoch 53/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.2119\n",
      "Epoch 54/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.2014\n",
      "Epoch 55/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.1960\n",
      "Epoch 56/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.1921\n",
      "Epoch 57/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.1933\n",
      "Epoch 58/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.2022\n",
      "Epoch 59/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.1903\n",
      "Epoch 60/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.2016\n",
      "Epoch 61/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1868\n",
      "Epoch 62/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1967\n",
      "Epoch 63/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.1899\n",
      "Epoch 64/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.1930\n",
      "Epoch 65/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.1850\n",
      "Epoch 66/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.1812\n",
      "Epoch 67/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1924\n",
      "Epoch 68/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.1749\n",
      "Epoch 69/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.1714\n",
      "Epoch 70/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.1804\n",
      "Epoch 71/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1779\n",
      "Epoch 72/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1641\n",
      "Epoch 73/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1648\n",
      "Epoch 74/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1592\n",
      "Epoch 75/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1576\n",
      "Epoch 76/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.1682\n",
      "Epoch 77/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.1747\n",
      "Epoch 78/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1664\n",
      "Epoch 79/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1527\n",
      "Epoch 80/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1515\n",
      "Epoch 81/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1490\n",
      "Epoch 82/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1575\n",
      "Epoch 83/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1557\n",
      "Epoch 84/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1697\n",
      "Epoch 85/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1533\n",
      "Epoch 86/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1403\n",
      "Epoch 87/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.1449\n",
      "Epoch 88/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1642\n",
      "Epoch 89/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1598\n",
      "Epoch 90/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1495\n",
      "Epoch 91/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1369\n",
      "Epoch 92/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1384\n",
      "Epoch 93/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1389\n",
      "Epoch 94/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1332\n",
      "Epoch 95/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1297\n",
      "Epoch 96/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.1283\n",
      "Epoch 97/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1278\n",
      "Epoch 98/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1388\n",
      "Epoch 99/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.1253\n",
      "Epoch 100/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1233\n",
      "Epoch 101/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1281\n",
      "Epoch 102/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1271\n",
      "Epoch 103/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1420\n",
      "Epoch 104/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1357\n",
      "Epoch 105/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1280\n",
      "Epoch 106/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1219\n",
      "Epoch 107/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1297\n",
      "Epoch 108/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.1361\n",
      "Epoch 109/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1409\n",
      "Epoch 110/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.1207\n",
      "Epoch 111/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.1176\n",
      "Epoch 112/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1219\n",
      "Epoch 113/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1245\n",
      "Epoch 114/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1192\n",
      "Epoch 115/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1227\n",
      "Epoch 116/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1254\n",
      "Epoch 117/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1243\n",
      "Epoch 118/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.1222\n",
      "Epoch 119/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1101\n",
      "Epoch 120/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1128\n",
      "Epoch 121/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1053\n",
      "Epoch 122/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1137\n",
      "Epoch 123/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1087\n",
      "Epoch 124/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1226\n",
      "Epoch 125/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1374\n",
      "Epoch 126/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1108\n",
      "Epoch 127/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1151\n",
      "Epoch 128/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1328\n",
      "Epoch 129/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1351\n",
      "Epoch 130/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1169\n",
      "Epoch 131/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1169\n",
      "Epoch 132/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1172\n",
      "Epoch 133/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1137\n",
      "Epoch 134/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1099\n",
      "Epoch 135/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1046\n",
      "Epoch 136/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1101\n",
      "Epoch 137/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.1194\n",
      "Epoch 138/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.1107\n",
      "Epoch 139/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.1113\n",
      "Epoch 140/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1016\n",
      "Epoch 141/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1068\n",
      "Epoch 142/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.1026\n",
      "Epoch 143/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1066\n",
      "Epoch 144/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1157\n",
      "Epoch 145/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.1112\n",
      "Epoch 146/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1095\n",
      "Epoch 147/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1033\n",
      "Epoch 148/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1020\n",
      "Epoch 149/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1082\n",
      "Epoch 150/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1105\n",
      "Epoch 151/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1087\n",
      "Epoch 152/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1028\n",
      "Epoch 153/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.1077\n",
      "Epoch 154/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1201\n",
      "Epoch 155/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1072\n",
      "Epoch 156/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0974\n",
      "Epoch 157/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0987\n",
      "Epoch 158/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1065\n",
      "Epoch 159/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1078\n",
      "Epoch 160/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0970\n",
      "Epoch 161/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0998\n",
      "Epoch 162/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1067\n",
      "Epoch 163/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1070\n",
      "Epoch 164/200\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1090\n",
      "Epoch 165/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1040\n",
      "Epoch 166/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1041\n",
      "Epoch 167/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1126\n",
      "Epoch 168/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1250\n",
      "Epoch 169/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1179\n",
      "Epoch 170/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1067\n",
      "Epoch 171/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.1043\n",
      "Epoch 172/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1106\n",
      "Epoch 173/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1068\n",
      "Epoch 174/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0966\n",
      "Epoch 175/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.1075\n",
      "Epoch 176/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.1068\n",
      "Epoch 177/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1146\n",
      "Epoch 178/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.1088\n",
      "Epoch 179/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0979\n",
      "Epoch 180/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0960\n",
      "Epoch 181/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.1070\n",
      "Epoch 182/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.1098\n",
      "Epoch 183/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0996\n",
      "Epoch 184/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0982\n",
      "Epoch 185/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1037\n",
      "Epoch 186/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.1017\n",
      "Epoch 187/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1086\n",
      "Epoch 188/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1025\n",
      "Epoch 189/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1054\n",
      "Epoch 190/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0967\n",
      "Epoch 191/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0965\n",
      "Epoch 192/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0941\n",
      "Epoch 193/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0922\n",
      "Epoch 194/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1002\n",
      "Epoch 195/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1167\n",
      "Epoch 196/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1402\n",
      "Epoch 197/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1144\n",
      "Epoch 198/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.0974\n",
      "Epoch 199/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.0982\n",
      "Epoch 200/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.1079\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    model.fit(x[cell_features], x[cell_features], batch_size = 1000, epochs = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d1ed96a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-25T18:45:40.085846Z",
     "iopub.status.busy": "2024-02-25T18:45:40.085492Z",
     "iopub.status.idle": "2024-02-25T18:45:40.108206Z",
     "shell.execute_reply": "2024-02-25T18:45:40.107323Z"
    },
    "papermill": {
     "duration": 0.178868,
     "end_time": "2024-02-25T18:45:40.110232",
     "exception": false,
     "start_time": "2024-02-25T18:45:39.931364",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# take the output of the encoded part\n",
    "encoder = tf.keras.Model(inputs = inputs, outputs = encoder_2)\n",
    "encoder.save('encoder_cell_features.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23444fb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-25T18:45:40.399709Z",
     "iopub.status.busy": "2024-02-25T18:45:40.399373Z",
     "iopub.status.idle": "2024-02-25T18:45:44.429301Z",
     "shell.execute_reply": "2024-02-25T18:45:44.428496Z"
    },
    "papermill": {
     "duration": 4.176838,
     "end_time": "2024-02-25T18:45:44.431299",
     "exception": false,
     "start_time": "2024-02-25T18:45:40.254461",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-07 23:49:46.655725: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-07 23:49:46.656205: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-03-07 23:49:46.656282: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-03-07 23:49:46.656350: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-03-07 23:49:46.656417: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2024-03-07 23:49:46.656481: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2024-03-07 23:49:46.656544: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2024-03-07 23:49:46.656606: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-03-07 23:49:46.656668: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-03-07 23:49:46.656678: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-03-07 23:49:46.657089: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 39/745 [>.............................] - ETA: 0s  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-07 23:49:46.954580: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 147075264 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "745/745 [==============================] - 1s 1ms/step\n",
      "125/125 [==============================] - 0s 1ms/step\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "745/745 [==============================] - 0s 496us/step\n",
      "125/125 [==============================] - 0s 522us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "encoder = load_model('encoder_gene_features.h5')\n",
    "train_gene_features = encoder.predict(x[gene_features])\n",
    "test_gene_features = encoder.predict(test[gene_features])\n",
    "\n",
    "encoder = load_model('encoder_cell_features.h5')\n",
    "train_cell_features = encoder.predict(x[cell_features])\n",
    "test_cell_features = encoder.predict(test[cell_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e84ce50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-25T18:45:44.729917Z",
     "iopub.status.busy": "2024-02-25T18:45:44.729581Z",
     "iopub.status.idle": "2024-02-25T18:45:44.765783Z",
     "shell.execute_reply": "2024-02-25T18:45:44.764952Z"
    },
    "papermill": {
     "duration": 0.187746,
     "end_time": "2024-02-25T18:45:44.768090",
     "exception": false,
     "start_time": "2024-02-25T18:45:44.580344",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_1_train = np.hstack((x['cp_type'].values.reshape(-1,1), x['cp_time'].values.reshape(-1, 1), x['cp_dose'].values.reshape(-1, 1),\n",
    "                        train_gene_features, train_cell_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29cb39d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-25T18:45:45.070088Z",
     "iopub.status.busy": "2024-02-25T18:45:45.069238Z",
     "iopub.status.idle": "2024-02-25T18:45:45.077613Z",
     "shell.execute_reply": "2024-02-25T18:45:45.076821Z"
    },
    "papermill": {
     "duration": 0.160833,
     "end_time": "2024-02-25T18:45:45.079661",
     "exception": false,
     "start_time": "2024-02-25T18:45:44.918828",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_1_test = np.hstack((test['cp_type'].values.reshape(-1,1), test['cp_time'].values.reshape(-1, 1), test['cp_dose'].values.reshape(-1, 1),\n",
    "                        test_gene_features, test_cell_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "597a8a29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-25T18:45:45.375918Z",
     "iopub.status.busy": "2024-02-25T18:45:45.375202Z",
     "iopub.status.idle": "2024-02-25T18:45:45.381043Z",
     "shell.execute_reply": "2024-02-25T18:45:45.380231Z"
    },
    "papermill": {
     "duration": 0.155918,
     "end_time": "2024-02-25T18:45:45.382986",
     "exception": false,
     "start_time": "2024-02-25T18:45:45.227068",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((23814, 498), (23814, 206))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_1_train.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b34569a",
   "metadata": {
    "papermill": {
     "duration": 0.148467,
     "end_time": "2024-02-25T18:45:45.679529",
     "exception": false,
     "start_time": "2024-02-25T18:45:45.531062",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## classifer chain - random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d083abc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-25T18:45:45.978815Z",
     "iopub.status.busy": "2024-02-25T18:45:45.978409Z",
     "iopub.status.idle": "2024-02-25T19:45:41.997393Z",
     "shell.execute_reply": "2024-02-25T19:45:41.996418Z"
    },
    "papermill": {
     "duration": 3596.324468,
     "end_time": "2024-02-25T19:45:42.152180",
     "exception": false,
     "start_time": "2024-02-25T18:45:45.827712",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 59min 26s, sys: 31.2 s, total: 59min 58s\n",
      "Wall time: 59min 56s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ClassifierChain(classifier=RandomForestClassifier(max_depth=7, n_estimators=75),\n",
       "                require_dense=[True, True])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ClassifierChain</label><div class=\"sk-toggleable__content\"><pre>ClassifierChain(classifier=RandomForestClassifier(max_depth=7, n_estimators=75),\n",
       "                require_dense=[True, True])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">classifier: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=7, n_estimators=75)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=7, n_estimators=75)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "ClassifierChain(classifier=RandomForestClassifier(max_depth=7, n_estimators=75),\n",
       "                require_dense=[True, True])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "classifier = ClassifierChain(classifier = RandomForestClassifier(max_depth = 7, n_estimators = 75),\n",
    "                                            require_dense=[True, True])\n",
    "classifier.fit(x_1_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "42341283",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-25T19:45:42.451229Z",
     "iopub.status.busy": "2024-02-25T19:45:42.450524Z",
     "iopub.status.idle": "2024-02-25T19:45:43.188762Z",
     "shell.execute_reply": "2024-02-25T19:45:43.187649Z"
    },
    "papermill": {
     "duration": 0.889162,
     "end_time": "2024-02-25T19:45:43.191138",
     "exception": false,
     "start_time": "2024-02-25T19:45:42.301976",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pickle.dump((classifier), open('random_forest_model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8412d02e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-25T19:45:43.490020Z",
     "iopub.status.busy": "2024-02-25T19:45:43.489665Z",
     "iopub.status.idle": "2024-02-25T19:45:57.362645Z",
     "shell.execute_reply": "2024-02-25T19:45:57.361763Z"
    },
    "papermill": {
     "duration": 14.024073,
     "end_time": "2024-02-25T19:45:57.365044",
     "exception": false,
     "start_time": "2024-02-25T19:45:43.340971",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction = classifier.predict_proba(x_1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "07a0eba0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-25T19:45:57.664503Z",
     "iopub.status.busy": "2024-02-25T19:45:57.663672Z",
     "iopub.status.idle": "2024-02-25T19:45:57.691799Z",
     "shell.execute_reply": "2024-02-25T19:45:57.690820Z"
    },
    "papermill": {
     "duration": 0.179115,
     "end_time": "2024-02-25T19:45:57.693859",
     "exception": false,
     "start_time": "2024-02-25T19:45:57.514744",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5-alpha_reductase_inhibitor</th>\n",
       "      <th>11-beta-hsd1_inhibitor</th>\n",
       "      <th>acat_inhibitor</th>\n",
       "      <th>acetylcholine_receptor_agonist</th>\n",
       "      <th>acetylcholine_receptor_antagonist</th>\n",
       "      <th>acetylcholinesterase_inhibitor</th>\n",
       "      <th>adenosine_receptor_agonist</th>\n",
       "      <th>adenosine_receptor_antagonist</th>\n",
       "      <th>adenylyl_cyclase_activator</th>\n",
       "      <th>adrenergic_receptor_agonist</th>\n",
       "      <th>...</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "      <th>sig_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.006538</td>\n",
       "      <td>0.013287</td>\n",
       "      <td>0.014692</td>\n",
       "      <td>0.000974</td>\n",
       "      <td>0.003533</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.012739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>0.001121</td>\n",
       "      <td>0.002305</td>\n",
       "      <td>0.001432</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001503</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>0.014237</td>\n",
       "      <td>0.000420</td>\n",
       "      <td>id_0004d9e33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.004645</td>\n",
       "      <td>0.009178</td>\n",
       "      <td>0.001411</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>0.002633</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.012644</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000741</td>\n",
       "      <td>0.002332</td>\n",
       "      <td>0.001428</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021163</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000336</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>id_001897cda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>0.005226</td>\n",
       "      <td>0.010553</td>\n",
       "      <td>0.000904</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>0.015759</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008161</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000563</td>\n",
       "      <td>0.003398</td>\n",
       "      <td>0.001641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003239</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>id_002429b5b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.013340</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.005656</td>\n",
       "      <td>0.011041</td>\n",
       "      <td>0.006006</td>\n",
       "      <td>0.000966</td>\n",
       "      <td>0.001797</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012086</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.000387</td>\n",
       "      <td>0.002293</td>\n",
       "      <td>0.001062</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001580</td>\n",
       "      <td>0.013578</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>id_00276f245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.009333</td>\n",
       "      <td>0.012943</td>\n",
       "      <td>0.001204</td>\n",
       "      <td>0.001105</td>\n",
       "      <td>0.002269</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010177</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.000866</td>\n",
       "      <td>0.001909</td>\n",
       "      <td>0.001392</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002339</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>id_0027f1083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor  acat_inhibitor  \\\n",
       "0                     0.000014                0.000242        0.000140   \n",
       "1                     0.000002                0.000016        0.000159   \n",
       "2                     0.000002                0.000007        0.000248   \n",
       "3                     0.000181                0.013340        0.000091   \n",
       "4                     0.000038                0.000032        0.000136   \n",
       "\n",
       "   acetylcholine_receptor_agonist  acetylcholine_receptor_antagonist  \\\n",
       "0                        0.006538                           0.013287   \n",
       "1                        0.004645                           0.009178   \n",
       "2                        0.005226                           0.010553   \n",
       "3                        0.005656                           0.011041   \n",
       "4                        0.009333                           0.012943   \n",
       "\n",
       "   acetylcholinesterase_inhibitor  adenosine_receptor_agonist  \\\n",
       "0                        0.014692                    0.000974   \n",
       "1                        0.001411                    0.000407   \n",
       "2                        0.000904                    0.000464   \n",
       "3                        0.006006                    0.000966   \n",
       "4                        0.001204                    0.001105   \n",
       "\n",
       "   adenosine_receptor_antagonist  adenylyl_cyclase_activator  \\\n",
       "0                       0.003533                    0.000004   \n",
       "1                       0.002633                    0.000008   \n",
       "2                       0.015759                    0.000000   \n",
       "3                       0.001797                    0.000000   \n",
       "4                       0.002269                    0.000000   \n",
       "\n",
       "   adrenergic_receptor_agonist  ...  trpv_agonist  trpv_antagonist  \\\n",
       "0                     0.012739  ...      0.000261         0.001121   \n",
       "1                     0.012644  ...      0.000037         0.000741   \n",
       "2                     0.008161  ...      0.000043         0.000563   \n",
       "3                     0.012086  ...      0.000172         0.000387   \n",
       "4                     0.010177  ...      0.000141         0.000866   \n",
       "\n",
       "   tubulin_inhibitor  tyrosine_kinase_inhibitor  \\\n",
       "0           0.002305                   0.001432   \n",
       "1           0.002332                   0.001428   \n",
       "2           0.003398                   0.001641   \n",
       "3           0.002293                   0.001062   \n",
       "4           0.001909                   0.001392   \n",
       "\n",
       "   ubiquitin_specific_protease_inhibitor  vegfr_inhibitor  vitamin_b  \\\n",
       "0                                    0.0         0.001503   0.000221   \n",
       "1                                    0.0         0.021163   0.000058   \n",
       "2                                    0.0         0.003239   0.000111   \n",
       "3                                    0.0         0.001580   0.013578   \n",
       "4                                    0.0         0.002339   0.000190   \n",
       "\n",
       "   vitamin_d_receptor_agonist  wnt_inhibitor        sig_id  \n",
       "0                    0.014237       0.000420  id_0004d9e33  \n",
       "1                    0.000336       0.000229  id_001897cda  \n",
       "2                    0.000298       0.000269  id_002429b5b  \n",
       "3                    0.000531       0.000144  id_00276f245  \n",
       "4                    0.000173       0.000169  id_0027f1083  \n",
       "\n",
       "[5 rows x 207 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame(prediction.todense(),columns=[i for i in target_cols])\n",
    "submission['sig_id'] = test['sig_id']\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "658d4b37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-25T19:45:57.994721Z",
     "iopub.status.busy": "2024-02-25T19:45:57.994359Z",
     "iopub.status.idle": "2024-02-25T19:45:59.628825Z",
     "shell.execute_reply": "2024-02-25T19:45:59.627668Z"
    },
    "papermill": {
     "duration": 1.788383,
     "end_time": "2024-02-25T19:45:59.631197",
     "exception": false,
     "start_time": "2024-02-25T19:45:57.842814",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30175dd3",
   "metadata": {},
   "source": [
    "![score](score.png)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 1651354,
     "sourceId": 19988,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30648,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3702.662871,
   "end_time": "2024-02-25T19:46:01.811821",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-02-25T18:44:19.148950",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
